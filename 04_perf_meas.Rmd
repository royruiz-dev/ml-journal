---
title: "04 Performance Measures"
author: "Roy Ruiz"
date: "2020-12-29"
output:
  html_document:
    toc: true
    toc_float: true
    df_print: paged
    collapsed: false
    number_sections: false
    toc_depth: 3
    #code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.width=10, message=FALSE, warning=FALSE, cache=TRUE)
```


# **04 Performance Measures**

*Last compiled:* **`r Sys.Date()`**


**Goal**

In the previous section, we predicted whether or not a product will be put on 'backorder' status using H2O model. We now take the H2O models developed to inspect, visualize, and communicate performance to business stakeholders.

These are some relevant questions to ask ponder:

<ul>
<li>How can I visualize the H2O Leaderboard?</li>
<li>How can I generate and work with H2O performance objects?</li>
<li>How can I analyze models using ROC and Precision vs. Recall Plots, which are essential for data science model selection?</li>
<li>How can I communicate the model benefits using Gain and Lift Plots, which are essential for executive communication?</li>
<li>How can I make a model diagnostic dashboard using the `cowplot` package?</li>
</ul>

The work performed here is broken down into multiple steps as follows:
<ol>
<li>Load libraries</li>
<li>Visualize the Leaderboard</li>
<li>Save multiple models for future use</li>
<li>Tune a model with Grid Search</li>
<li>Visualize trade-off between precision, recall and optimal threshold</li>
<li>Plot Receiving Operating Characteristic (ROC) curve</li>
<li>Plot Precision vs. Recall chart</li>
<li>Plot Gain and Lift charts</li>
<li>Develop an H2O Model Metrics dashboard with `cowplot` package</li>
</ol>

For this, I will be reusing the **Product Backorders** data set (source of raw data is linked below). You may download the data in case you want to try this code on your own.

Please note this is a continuation of the previous section.

*Raw data source*:<br />
```{r echo=FALSE}

# Product Backorders dataset
xfun::embed_file('00_raw_data/product_backorders.csv')

```


## Step 1: Load libraries

As a first step, please load `tidyverse` and `tidymodels` libraries. For details on what these libraries offer, please refer to the comments in the code block below.

```{r}
# STEP 1: Load Libraries ---
# Tidy, Transform, & Visualize
library(tidyverse)
#  library(tibble)    --> is a modern re-imagining of the data frame
#  library(readr)     --> provides a fast and friendly way to read rectangular data like csv
#  library(dplyr)     --> provides a grammar of data manipulation
#  library(magrittr)  --> offers a set of operators which make your code more readable (pipe operator)
#  library(tidyr)     --> provides a set of functions that help you get to tidy data
#  library(stringr)   --> provides a cohesive set of functions designed to make working with strings as easy as possible
#  library(ggplot2)   --> graphics

library(tidymodels)
# library(rsample)    --> provides infrastructure for efficient data splitting, resampling and cross validation.
# library(parsnip)    --> provides an API to many powerful modeling algorithms in R.
# library(recipes)    --> tidy interface to data pre-processing (making statistical transformations) tools for feature engineering (prior to modeling).
# library(workflows)  --> bundle your pre-processing, modeling, and post-processing together.
# library(tune)       --> helps you optimize the hyperparameters of your model and pre-processing steps.
# library(yardstick)  --> measures the effectiveness of models using performance metrics (metrics for model comparison).
# library(broom)      --> converts the information in common statistical R objects into user-friendly, predictable formats.
# library(dials)      --> creates and manages tuning parameters and parameter grids.

library(h2o)          # H2O modeling
library(ggthemes)     # Better themes for plotting and color palettes
library(glue)         # Implementation of interpreted string literals
library(cowplot)      # Provides various features to help create  publication-quality figures

```


If you haven't installed these packages, please install them by calling `install.packages(`*[name_of_package]*`)` in the R console. After installing, run the above code block again.


## Step 2: Visualize the Leaderboard

```{r fig.height=8}
# Visualize the H2O leaderboard to help with model selection
data_transformed_tbl <- automl_models_h2o@leaderboard %>%
  as_tibble() %>%
  select(-c(aucpr, mean_per_class_error, rmse, mse)) %>% 
  mutate(model_type = str_extract(model_id, "[^_]+")) %>%
  slice(1:n()) %>% 
  rownames_to_column(var = "rowname") %>%
  # Visually this step will not change anything
  # It reorders the factors under the hood
  mutate(
    model_id   = as_factor(model_id) %>% reorder(auc),
    model_type = as.factor(model_type)
  ) %>% 
  pivot_longer(cols = -c(model_id, model_type, rowname), 
               names_to = "key", 
               values_to = "value", 
               names_transform = list(key = forcats::fct_inorder)
  ) %>% 
  mutate(model_id = paste0(rowname, ". ", model_id) %>% as_factor() %>% fct_rev())

# Perform visualization
data_transformed_tbl %>%
  ggplot(aes(value, model_id, color = model_type)) +
  geom_point(size = 3) +
  geom_label(aes(label = round(value, 3), hjust = "inward"), show.legend = F) +
  scale_color_gdocs() +
  # Facet to break out logloss and auc
  facet_wrap(~ toupper(key), scales = "free_x") +
  labs(title = "Leaderboard Metrics",
       subtitle = paste0("Ordered by: ", "AUC (Area Under the Curve)"),
       y = "Model Postion, Model ID", x = "") + 
  theme(legend.position = "bottom")
```


## Step 3: Save multiple models for future use

```{r eval=FALSE}
# Extracts an H2O model name by a position so can more easily use h2o.getModel()
extract_h2o_model_name_by_position <- function(h2o_leaderboard, n = 1, verbose = T) {
  
  model_name <- h2o_leaderboard %>%
    as.tibble() %>%
    slice(n) %>%
    pull(model_id)
  
  if (verbose) message(model_name)
  
  return(model_name)
  
}

# Save multiple models by extracting from leaderboard
for (num in c(1,2,3,4,13,14,15,16)){
  automl_models_h2o@leaderboard %>% 
    extract_h2o_model_name_by_position(num) %>%
    h2o.getModel() %>%
    h2o.saveModel(path = "00_h2o_models/03/")
  }
```


## Step 4: Tune a model with Grid Search

```{r}
# Loading Distributed Random Forest model
drf_h2o <- h2o.loadModel("00_h2o_models/03/DRF_1_AutoML_20210105_210409")

# Take a look at the metrics on the training data set
drf_h2o

# We want to see how it performs for the testing data frame
# Make sure to convert it to an h20 object
h2o.performance(drf_h2o, newdata = as.h2o(test_tbl))
```
```{r eval=FALSE}
drf_grid_01 <- h2o.grid(
  
  # See help page for available algorithms via ?h2o.grid()
  algorithm = "randomForest",
  
  # Use the same as the object
  grid_id = "drf_grid_01",
  
  # predictor and response variables
  x = x,
  y = y,
  
  # training and validation frame and crossfold validation
  training_frame   = train_h2o,
  validation_frame = valid_h2o,
  nfolds = 5,
  
  # Hyperparamters: Use drf_h2o@allparameters to see all
  hyper_params = list(
    # Use different number of trees to find a better model
    ntrees = c(5, 10, 15, 20, 50, 60, 70, 120, 140, 160, 250)
  )
)
```
```{r}

# Ordered by increasing logloss
drf_grid_01

# Ordered by decreasing auc
h2o.getGrid(grid_id = "drf_grid_01", sort_by = "auc", decreasing = TRUE)

drf_grid_01_model_10 <- h2o.getModel("drf_grid_01_model_10")
drf_grid_01_model_10 %>% h2o.auc(train = T, valid = T, xval = T)

# The model is not overfitting because there's a small difference between the
# training AUC and the validation / cross validation AUC

# Run it with test data and compare to the results from "drf_h2o" model above
drf_grid_01_model_10 %>%
  h2o.performance(newdata = as.h2o(test_tbl))
```


## Step 5: Visualize trade-off between precision, recall and optimal threshold

```{r eval=FALSE}
# Loading top H2O model
stacked_ensemble_h2o <- h2o.loadModel("00_h2o_models/03/StackedEnsemble_AllModels_AutoML_20210105_210409")

performance_h2o <- h2o.performance(stacked_ensemble_h2o, newdata = as.h2o(test_tbl))
```
```{r fig.height=8}
typeof(performance_h2o)
performance_h2o %>% slotNames()

performance_tbl <- performance_h2o %>%
  h2o.metric() %>%
  as.tibble() 

performance_tbl %>% 
  glimpse()

theme_new <- theme(
  legend.position  = "bottom",
  legend.title = element_text(size = 11),
  legend.text = element_text(size = 9),
  legend.key       = element_blank(),
  panel.background = element_rect(fill   = "transparent"),
  panel.border     = element_rect(color = "black", fill = NA, size = 0.5),
  panel.grid.major = element_line(color = "grey", size = 0.333)
)

performance_tbl %>%
  filter(f1 == max(f1))

performance_tbl %>%
  ggplot(aes(x = threshold)) +
  geom_line(aes(y = precision, color = "Precision"), size = 0.5) +
  geom_line(aes(y = recall, color = "Recall"), size = 0.5) +
  scale_color_manual(breaks = c("Precision", "Recall"),
                     values = c("blue", "red")) +
  # Insert line where precision and recall are harmonically optimized
  geom_vline(xintercept = h2o.find_threshold_by_max_metric(performance_h2o, "f1")) +
  labs(
    title = "Precision vs. Recall",
    y = "Value",
    x = "Threshold") +
  theme_new
```


## Step 6: Plot Receiving Operating Characteristic (ROC) curve

```{r eval=FALSE}
load_model_performance_metrics <- function(path, test_tbl) {
  
  model_h2o <- h2o.loadModel(path)
  perf_h2o  <- h2o.performance(model_h2o, newdata = as.h2o(test_tbl)) 
  
  perf_h2o %>%
    h2o.metric() %>%
    as_tibble() %>%
    mutate(auc = h2o.auc(perf_h2o)) %>%
    select(tpr, fpr, auc)
  
}

model_metrics_tbl <- fs::dir_info(path = "00_h2o_models/03/") %>%
  select(path) %>%
  mutate(metrics = map(path, load_model_performance_metrics, test_tbl)) %>%
  unnest(cols = metrics)
```
```{r fig.height=8}
model_metrics_tbl %>%
  arrange(desc(auc)) %>%
  mutate(
    # Extract the model names
    PATH = str_split(path, pattern = "/", simplify = T)[,3] %>% as_factor(),
    AUC  = auc %>% round(4) %>% as.character() %>% as_factor()
  ) %>%
  ggplot(aes(fpr, tpr, color = PATH, linetype = AUC)) +
  geom_line(size = 0.75) +
  scale_color_gdocs() +
  # just for demonstration purposes
  geom_abline(color = "black", linetype = "dotted", size = 0.75) +
  theme_minimal() +
  theme_new +
  theme(legend.direction = "vertical") +
  labs(title = "ROC (Receiver Operating Characteristic) Plot",
       subtitle = "Performance of Top 4 & Bottom 4 Performing Models",
       y = "TPR",
       x = "FPR")
```


## Step 7: Plot Precision vs. Recall chart

```{r eval=FALSE}
load_model_performance_metrics <- function(path, test_tbl) {
  
  model_h2o <- h2o.loadModel(path)
  perf_h2o  <- h2o.performance(model_h2o, newdata = as.h2o(test_tbl)) 
  
  perf_h2o %>%
    h2o.metric() %>%
    as_tibble() %>%
    mutate(auc = h2o.auc(perf_h2o)) %>%
    select(tpr, fpr, auc, precision, recall)
  
}

model_metrics_tbl <- fs::dir_info(path = "00_h2o_models/03/") %>%
  select(path) %>%
  mutate(metrics = map(path, load_model_performance_metrics, test_tbl)) %>%
  unnest(cols = metrics)
```
```{r fig.height=8}
model_metrics_tbl %>%
  arrange(desc(auc)) %>%
  mutate(
    # Extract the model names
    PATH = str_split(path, pattern = "/", simplify = T)[,3] %>% as_factor(),
    AUC  = auc %>% round(4) %>% as.character() %>% as_factor()
  ) %>%
  ggplot(aes(recall, precision, color = PATH, linetype = AUC)) +
  geom_line(size = 0.75) +
  scale_color_gdocs() +
  theme_minimal() +
  theme_new + 
  theme(legend.direction = "vertical") +
  labs(title = "Precision vs Recall Plot",
       subtitle = "Performance of Top 4 & Bottom 4 Performing Models",
       y = "Precision",
       x = "Recall")
```


## Step 8: Plot Gain and Lift charts

```{r fig.height=8}
# Table for Gain and Lift plotting
gain_lift_tbl <- performance_h2o %>%
  h2o.gainsLift() %>%
  as.tibble()

## Gain Plot
gain_transformed_tbl <- gain_lift_tbl %>% 
  select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift) %>%
  select(-contains("lift")) %>%
  mutate(baseline = cumulative_data_fraction) %>%
  rename(gain     = cumulative_capture_rate) %>%
  # prepare the data for the plotting (for the color and group aesthetics)
  pivot_longer(cols = c(gain, baseline), values_to = "value", names_to = "key")

gain_transformed_tbl %>%
  ggplot(aes(x = cumulative_data_fraction, y = value, color = key)) +
  geom_line(size = 0.5) +
  scale_color_gdocs() +
  theme_minimal() +
  theme_new +
  labs(title = "Gain Chart",
       x = "Cumulative Data Fraction",
       y = "Gain")

## Lift Plot
lift_transformed_tbl <- gain_lift_tbl %>% 
  select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift) %>%
  select(-contains("capture")) %>%
  mutate(baseline = 1) %>%
  rename(lift = cumulative_lift) %>%
  pivot_longer(cols = c(lift, baseline), values_to = "value", names_to = "key")

lift_transformed_tbl %>%
  ggplot(aes(x = cumulative_data_fraction, y = value, color = key)) +
  geom_line(size = 0.5) +
  scale_color_gdocs() +
  theme_minimal() +
  theme_new +
  labs(title = "Lift Chart",
       x = "Cumulative Data Fraction",
       y = "Lift")
```


## Step 9: Develop an H2O Model Metrics dashboard with 'cowplot' package

```{r fig.height=14}
plot_h2o_performance <- function(h2o_leaderboard, newdata, order_by = c("auc", "logloss"),
                                 top_models = 2, bottom_models = 2, size = 1.5) {
  
  # Inputs
  leaderboard_tbl <- h2o_leaderboard %>%
    as_tibble() %>%
    slice(1:top_models,(n()-bottom_models+1):n())
  
  newdata_tbl <- newdata %>%
    as_tibble()
  
  # Selecting the first, if nothing is provided
  order_by      <- tolower(order_by[[1]]) 
  
  # Convert string stored in a variable to column name (symbol)
  order_by_expr <- rlang::sym(order_by)
  
  # Turn of the progress bars ( opposite h2o.show_progress())
  h2o.no_progress()
  
  # 1. Model Metrics
  get_model_performance_metrics <- function(model_id, test_tbl) {
    
    model_h2o <- h2o.getModel(model_id)
    perf_h2o  <- h2o.performance(model_h2o, newdata = as.h2o(test_tbl))
    
    perf_h2o %>%
      h2o.metric() %>%
      as.tibble() %>%
      select(threshold, tpr, fpr, precision, recall)
  }
  
  model_metrics_tbl <- leaderboard_tbl %>%
    mutate(metrics = map(model_id, get_model_performance_metrics, newdata_tbl)) %>%
    unnest(cols = metrics) %>%
    mutate(model_id = as_factor(model_id) %>%
             # programmatically reorder factors depending on order_by
             fct_reorder(!! order_by_expr, 
                         .desc = ifelse(order_by == "auc", TRUE, FALSE)),
           auc      = auc %>% 
             round(3) %>% 
             as.character() %>% 
             as_factor() %>% 
             fct_reorder(as.numeric(model_id)),
           logloss  = logloss %>% 
             round(4) %>% 
             as.character() %>% 
             as_factor() %>% 
             fct_reorder(as.numeric(model_id)))
  
  ## 1A. ROC Plot
  p1 <- model_metrics_tbl %>%
    ggplot(aes(fpr, tpr, color = model_id, linetype = !! order_by_expr)) +
    geom_line(size = size) +
    scale_color_gdocs() +
    theme_minimal() +
    theme_new +
    labs(title = "ROC", x = "FPR", y = "TPR") +
    theme(legend.direction = "vertical") 
  
  ## 1B. Precision vs Recall
  p2 <- model_metrics_tbl %>%
    ggplot(aes(recall, precision, color = model_id, linetype = !! order_by_expr)) +
    geom_line(size = size) +
    scale_color_gdocs() +
    theme_minimal() +
    theme_new +
    labs(title = "Precision Vs Recall", x = "Recall", y = "Precision") +
    theme(legend.position = "none") 
  
  ## 2. Gain / Lift
  get_gain_lift <- function(model_id, test_tbl) {
    
    model_h2o <- h2o.getModel(model_id)
    perf_h2o  <- h2o.performance(model_h2o, newdata = as.h2o(test_tbl)) 
    
    perf_h2o %>%
      h2o.gainsLift() %>%
      as.tibble() %>%
      select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift)
  }
  
  gain_lift_tbl <- leaderboard_tbl %>%
    mutate(metrics = map(model_id, get_gain_lift, newdata_tbl)) %>%
    unnest(cols = metrics) %>%
    mutate(model_id = as_factor(model_id) %>% 
             fct_reorder(!! order_by_expr, 
                         .desc = ifelse(order_by == "auc", TRUE, FALSE)),
           auc  = auc %>% 
             round(4) %>% 
             as.character() %>% 
             as_factor() %>% 
             fct_reorder(as.numeric(model_id)),
           logloss = logloss %>% 
             round(4) %>% 
             as.character() %>% 
             as_factor() %>% 
             fct_reorder(as.numeric(model_id))) %>%
    rename(gain = cumulative_capture_rate,
           lift = cumulative_lift) 
  
  ## 2A. Gain Plot
  p3 <- gain_lift_tbl %>%
    ggplot(aes(cumulative_data_fraction, gain, 
               color = model_id, linetype = !! order_by_expr)) +
    geom_line(size = size,) +
    geom_segment(x = 0, y = 0, xend = 1, yend = 1, 
                 color = "red", size = size, linetype = "dotted") +
    scale_color_gdocs() +
    theme_minimal() +
    theme_new +
    expand_limits(x = c(0, 1), y = c(0, 1)) +
    labs(title = "Gain", x = "Cumulative Data Fraction", y = "Gain") +
    theme(legend.position = "none")
  
  ## 2B. Lift Plot
  p4 <- gain_lift_tbl %>%
    ggplot(aes(cumulative_data_fraction, lift, 
               color = model_id, linetype = !! order_by_expr)) +
    geom_line(size = size) +
    geom_segment(x = 0, y = 1, xend = 1, yend = 1, 
                 color = "red", size = size, linetype = "dotted") +
    scale_color_gdocs() +
    theme_minimal() +
    theme_new +
    expand_limits(x = c(0, 1), y = c(0, 1)) +
    labs(title = "Lift", x = "Cumulative Data Fraction", y = "Lift") +
    theme(legend.position = "none")
  
  ### Combine using cowplot
  # cowplot::get_legend extracts a legend from a ggplot object
  p_legend <- get_legend(p1)
  
  # Remove legend from p1
  p1 <- p1 + theme(legend.position = "none")
  
  # cowplot::plt_grid() combines multiple ggplots into a single cowplot object
  p <- cowplot::plot_grid(p1, p2, p3, p4, ncol = 2)
  
  # cowplot::ggdraw() sets up a drawing layer
  p_title <- ggdraw() + 
    
    # cowplot::draw_label() draws text on a ggdraw layer / ggplot object
    draw_label(glue("Metrics for Top {top_models} & Bottom {bottom_models} H2O Models"), 
               size = 18, fontface = "bold", color = "#2C3E50")
  
  p_subtitle <- ggdraw() + 
    draw_label(glue("Ordered by {toupper(order_by)}"), 
               size = 10, color = "#2C3E50")
  
  # Combine everything
  ret <- plot_grid(p_title, p_subtitle, p, p_legend, 
                   # Adjust the relative spacing, so that the legends always fits
                   ncol = 1, rel_heights = c(0.05, 0.05, 1, 0.05 * (top_models + bottom_models)))
  
  h2o.show_progress()
  
  return(ret)
}

automl_models_h2o@leaderboard %>%
  plot_h2o_performance(newdata = test_tbl, order_by = "logloss", 
                       size = 0.75, bottom_models = 4, top_models = 4)
```

<hr>
<center>This concludes the Performance Measures section in `R`!<br /><br />Made with &hearts;<br />~Roy Ruiz~</center>